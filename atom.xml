<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://flybiubiu.github.io</id>
    <title>Gridea</title>
    <updated>2021-03-18T13:03:51.121Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://flybiubiu.github.io"/>
    <link rel="self" href="https://flybiubiu.github.io/atom.xml"/>
    <subtitle>Workhard!</subtitle>
    <logo>https://flybiubiu.github.io/images/avatar.png</logo>
    <icon>https://flybiubiu.github.io/favicon.ico</icon>
    <rights>All rights reserved 2021, Gridea</rights>
    <entry>
        <title type="html"><![CDATA[878. Nth Magical Number]]></title>
        <id>https://flybiubiu.github.io/post/eiwMVQ5jp/</id>
        <link href="https://flybiubiu.github.io/post/eiwMVQ5jp/">
        </link>
        <updated>2021-03-18T12:41:25.000Z</updated>
        <content type="html"><![CDATA[<p>HARD<br>
A positive integer is magical if it is divisible by either a or b.</p>
<p>Given the three integers n, a, and b, return the nth magical number. Since the answer may be very large, return it modulo 109 + 7.</p>
<p>Example 1:</p>
<p>Input: n = 1, a = 2, b = 3<br>
Output: 2<br>
Example 2:</p>
<p>Input: n = 4, a = 2, b = 3<br>
Output: 6<br>
Example 3:</p>
<p>Input: n = 5, a = 2, b = 4<br>
Output: 10<br>
Example 4:</p>
<p>Input: n = 3, a = 6, b = 4<br>
Output: 8</p>
<p>Constraints:</p>
<p>1 &lt;= n &lt;= 109<br>
2 &lt;= a, b &lt;= 4 * 104</p>
<p>class Solution {<br>
public:<br>
int nthMagicalNumber(int n, int a, int b) {<br>
int MOD = 1e9 + 7;<br>
int L = a * b / gcd(a, b);<br>
long long lo = 0;<br>
long long hi = (long) 1e15;<br>
while(lo &lt; hi)<br>
{<br>
long long mi = lo + (hi - lo) / 2;<br>
if (mi / a  + mi / b - mi / L &lt; n)<br>
lo = mi + 1;<br>
else<br>
hi = mi;<br>
}<br>
return (int)(lo % MOD);<br>
}<br>
};</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[video SR]]></title>
        <id>https://flybiubiu.github.io/post/rBi6GqIQI/</id>
        <link href="https://flybiubiu.github.io/post/rBi6GqIQI/">
        </link>
        <updated>2021-03-18T12:25:44.000Z</updated>
        <content type="html"><![CDATA[<p>*1.TDAN: Temporally-Deformable Alignment Network for Video Super-Resolution(做不了)<br>
pytorch-0.3.1<br>
an NVIDIA 1080TI GPU<br>
github:https://github.com/YapengTian/TDAN-VSR-CVPR-2020<br>
ps:<br>
由于pytorch-0.3.1 做不了<br>
*2.Zooming Slow-Mo: Fast and Accurate One-Stage Space-Time Video Super-Resolution.(尝试失败, 3090不支持pytorch1.4,导致里面的DCNv2版本没法编译)<br>
PyTorch &gt;= 1.1<br>
(一张Nvidia Titan XP GPU.)<br>
github:https://github.com/Mukosame/Zooming-Slow-Mo-CVPR-2020<br>
ps:<br>
由于之前接触过一点点这个项目, 里面有一个可变形模块DCNv2。当时这个模块需要pytorch-1.4<br>
借用的是https://github.com/CharlesShang/DCNv2<br>
后来有人改进了这个模块可以在3090上编译https://github.com/MatthewHowe/DCNv2(失败)<br>
*3.Video Super-resolution with Temporal Group Attention (TGA)(不能)(先看论文)<br>
PyTorch 1.1<br>
(8 Nvidia Tesla V100 GPUs)<br>
github:https://github.com/junpan19/VSR_TGA<br>
ps:<br>
8块v100，不知道一块3090会跑几天<br>
RuntimeError: CUDA out of memory. Tried to allocate 648.00 MiB (GPU 0; 23.70 GiB total capacity; 21.72 GiB already allocated; 169.25 MiB free; 22.17 GiB reserved in total by PyTorch)<br>
*4.Space-Time-Aware Multi-Resolution Video Enhancement(显存不够)(数据集特别大)<br>
PyTorch &gt;= 1.0.0<br>
NVIDIA Tesla V100 GPUs(具体不知道几块v100)<br>
github:https://github.com/alterzero/STARnet<br>
RuntimeError: CUDA out of memory. Tried to allocate 280.00 MiB (GPU 0; 23.70 GiB total capacity; 21.96 GiB already allocated; 113.25 MiB free; 22.23 GiB reserved in total by PyTorch)<br>
*5.FISR: Deep Joint Frame Interpolation and Super-Resolution with A Multi-scale Temporal Loss（做不了）<br>
Tensorflow 1.13<br>
NVIDIA TITAN Xp GPU<br>
github:https://github.com/JihyongOh/FISR<br>
*6.Video Face Super-Resolution with Motion-Adaptive Feedback Cell(不能做, 没代码)<br>
one Titan X Pascal GPU.<br>
*7.JSI-GAN: GAN-Based Joint Super-Resolution and Inverse Tone-Mapping with Pixel-Wise Task-Specific Filters for UHD HDR Video(没代码)<br>
Tensorflow 1.13<br>
*8.VESR-Net: The Winning Solution to Youku Video Enhancement and Super-Resolution Challenge(无代码)<br>
9.STVUN: Deep Space-Time Video Upsampling Networks(貌似比FISR好)(可以试试)(没有train代码,只有test)<br>
Pytorch=1.2<br>
Nvidia Geforce Titan X<br>
github:https://github.com/JaeYeonKang/STVUN-Pytorch<br>
10.MuCAN: Multi-Correspondence Aggregation Network for Video Super-Resolution(没train代码，只有test)<br>
eight NVIDIA GeForce GTX 1080TiGPUs<br>
github:https://github.com/Jia-Research-Lab/Simple-SR<br>
11.Video Super-Resolution with Recurrent Structure-Detail Network (RSDN)(暂无train带代码)<br>
pytorch 1.1<br>
8 Nvidia Tesla V100 GPUs for training.<br>
github:https://github.com/junpan19/RSDN<br>
12.Neural Supersampling for Real-time Rendering(还未完工)<br>
github:https://github.com/IMAC-projects/NSRR-PyTorch<br>
13.Video Restoration with Enhanced Deformable Convolutional Networks(正在尝试)<br>
8 NVIDIA Titan Xp GPUs<br>
github:https://github.com/xinntao/EDVR</p>
]]></content>
    </entry>
</feed>